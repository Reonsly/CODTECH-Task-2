import socket
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

def scan_ports(host, ports):
    open_ports = []
    for port in ports:
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            s.settimeout(1)
            result = s.connect_ex((host, port))
            if result == 0:
                open_ports.append(port)
            s.close()
        except Exception as e:
            print(f"Error scanning port {port}: {e}")
    return open_ports

def scan_website(url):
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.title.string
        return title
    except Exception as e:
        print(f"Error scanning website {url}: {e}")
        return None

def main():
    target = input("Enter the target IP address or domain name: ")
    ports = [21, 22, 23, 25, 53, 80, 110, 143, 443, 3306, 3389]
    
    print("Scanning for open ports...")
    open_ports = scan_ports(target, ports)
    if open_ports:
        print("Open ports found:", open_ports)
    else:
        print("No open ports found.")
    
    print("Scanning for website title...")
    parsed_url = urlparse(f"http://{target}")
    website_title = scan_website(parsed_url.geturl())
    if website_title:
        print("Website title:", website_title)
    else:
        print("Unable to retrieve website title.")

if __name__ == "__main__":
    main()
